{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-04T12:56:50.244542Z",
     "iopub.status.busy": "2026-01-04T12:56:50.244277Z",
     "iopub.status.idle": "2026-01-04T12:56:56.036509Z",
     "shell.execute_reply": "2026-01-04T12:56:56.035730Z",
     "shell.execute_reply.started": "2026-01-04T12:56:50.244506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q faiss-cpu transformers tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T12:56:56.037988Z",
     "iopub.status.busy": "2026-01-04T12:56:56.037742Z",
     "iopub.status.idle": "2026-01-04T12:57:22.185991Z",
     "shell.execute_reply": "2026-01-04T12:57:22.185351Z",
     "shell.execute_reply.started": "2026-01-04T12:56:56.037961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 12:57:08.204006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767531428.369503     102 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767531428.416126     102 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767531428.806898     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767531428.806942     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767531428.806945     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767531428.806948     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    DPRQuestionEncoder,\n",
    "    DPRContextEncoder,\n",
    "    DPRQuestionEncoderTokenizerFast,\n",
    "    DPRContextEncoderTokenizerFast\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T12:57:22.188174Z",
     "iopub.status.busy": "2026-01-04T12:57:22.187683Z",
     "iopub.status.idle": "2026-01-04T12:57:22.192435Z",
     "shell.execute_reply": "2026-01-04T12:57:22.191882Z",
     "shell.execute_reply.started": "2026-01-04T12:57:22.188149Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T12:57:22.193723Z",
     "iopub.status.busy": "2026-01-04T12:57:22.193434Z",
     "iopub.status.idle": "2026-01-04T12:57:33.062944Z",
     "shell.execute_reply": "2026-01-04T12:57:33.062127Z",
     "shell.execute_reply.started": "2026-01-04T12:57:22.193695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4a9690d6584b658588ddac2bd144a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41181afbc0e743fc989cf8902e5d49b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9bfea7e4654cc8960547e189bd46c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4760c7bbfc404dd59d8b98f8746b1e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/493 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194ce67283dd4549850809b2dd44af68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550222b17f264247ad869011f64a5be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b849ee5e4dc34a258364346fbd95f4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c7ad1c096746378f711c33a5e74538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/492 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9aff1f8e0f74f0598da1f8ffec580d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fa5067c942466aa2d743cf6a5202af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e649796f734e7195410d110e679944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DPRContextEncoder(\n",
       "  (ctx_encoder): DPREncoder(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_tokenizer = DPRQuestionEncoderTokenizerFast.from_pretrained(\n",
    "    \"facebook/dpr-question_encoder-single-nq-base\"\n",
    ")\n",
    "p_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(\n",
    "    \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    ")\n",
    "\n",
    "q_encoder = DPRQuestionEncoder.from_pretrained(\n",
    "    \"facebook/dpr-question_encoder-single-nq-base\"\n",
    ").to(device)\n",
    "\n",
    "p_encoder = DPRContextEncoder.from_pretrained(\n",
    "    \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    ").to(device)\n",
    "\n",
    "q_encoder.eval()\n",
    "p_encoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T12:57:33.064562Z",
     "iopub.status.busy": "2026-01-04T12:57:33.064017Z",
     "iopub.status.idle": "2026-01-04T12:57:33.069687Z",
     "shell.execute_reply": "2026-01-04T12:57:33.068752Z",
     "shell.execute_reply.started": "2026-01-04T12:57:33.064534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "    q_encoder = torch.nn.DataParallel(q_encoder)\n",
    "    p_encoder = torch.nn.DataParallel(p_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T12:57:33.070948Z",
     "iopub.status.busy": "2026-01-04T12:57:33.070620Z",
     "iopub.status.idle": "2026-01-04T12:57:33.082815Z",
     "shell.execute_reply": "2026-01-04T12:57:33.082012Z",
     "shell.execute_reply.started": "2026-01-04T12:57:33.070923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def build_dpr_passages_capped(\n",
    "    file_path,\n",
    "    max_distractors_per_doc=5,\n",
    "    seed=42\n",
    "):\n",
    "    random.seed(seed)\n",
    "    passages = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            ex = json.loads(line)\n",
    "\n",
    "            doc_tokens = ex[\"document_text\"].split()\n",
    "            candidates = ex[\"long_answer_candidates\"]\n",
    "            ann = ex[\"annotations\"][0]\n",
    "            la = ann[\"long_answer\"]\n",
    "\n",
    "            # --- Gold passage ---\n",
    "            gold_passage = None\n",
    "            gold_idx = la.get(\"candidate_index\", -1)\n",
    "\n",
    "            if la[\"start_token\"] != -1:\n",
    "                gold_passage = \" \".join(\n",
    "                    doc_tokens[la[\"start_token\"]:la[\"end_token\"]]\n",
    "                )\n",
    "                passages.append(gold_passage)\n",
    "\n",
    "            # --- Collect top-level distractors ---\n",
    "            distractors = []\n",
    "            for i, c in enumerate(candidates):\n",
    "                if not c[\"top_level\"]:\n",
    "                    continue\n",
    "                if i == gold_idx:\n",
    "                    continue\n",
    "\n",
    "                text = \" \".join(\n",
    "                    doc_tokens[c[\"start_token\"]:c[\"end_token\"]]\n",
    "                )\n",
    "                distractors.append(text)\n",
    "\n",
    "            # --- Sample fixed number of distractors ---\n",
    "            if distractors:\n",
    "                sampled = random.sample(\n",
    "                    distractors,\n",
    "                    min(max_distractors_per_doc, len(distractors))\n",
    "                )\n",
    "                passages.extend(sampled)\n",
    "\n",
    "    return passages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T12:57:33.084030Z",
     "iopub.status.busy": "2026-01-04T12:57:33.083736Z",
     "iopub.status.idle": "2026-01-04T13:06:10.772704Z",
     "shell.execute_reply": "2026-01-04T13:06:10.771879Z",
     "shell.execute_reply.started": "2026-01-04T12:57:33.084006Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee198a91593147839c65c847c0384e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total passages: 1368573\n",
      "Example passage:\n",
      " <P> A common example of permission marketing is a newsletter sent to an advertising firm 's customers . Such newsletters inform customers of upcoming events or promotions , or new products . In this type of advertising , a company that wants to send a newsletter to their customers may ask them at th\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/input/the-natural-questions-dataset/simplified-nq-train.jsonl\"\n",
    "\n",
    "passages = build_dpr_passages_capped(\n",
    "    file_path,\n",
    "    max_distractors_per_doc=4\n",
    ")\n",
    "\n",
    "print(\"Total passages:\", len(passages))\n",
    "print(\"Example passage:\\n\", passages[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T13:06:10.774291Z",
     "iopub.status.busy": "2026-01-04T13:06:10.773758Z",
     "iopub.status.idle": "2026-01-04T13:06:10.779436Z",
     "shell.execute_reply": "2026-01-04T13:06:10.778851Z",
     "shell.execute_reply.started": "2026-01-04T13:06:10.774267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def encode_passages(passages, batch_size=32, max_length=512):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in tqdm(\n",
    "        range(0, len(passages), batch_size),\n",
    "        desc=\"Encoding passages (2 GPUs)\"\n",
    "    ):\n",
    "        batch = passages[i:i + batch_size]\n",
    "\n",
    "        inputs = p_tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = p_encoder(**inputs)\n",
    "            # ✅ DPR embedding lives here\n",
    "            emb = outputs.pooler_output\n",
    "\n",
    "        emb = emb.cpu().numpy()\n",
    "        faiss.normalize_L2(emb)   # ✅ cosine similarity\n",
    "\n",
    "        all_embeddings.append(emb)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T13:06:10.780713Z",
     "iopub.status.busy": "2026-01-04T13:06:10.780381Z",
     "iopub.status.idle": "2026-01-04T20:37:33.276700Z",
     "shell.execute_reply": "2026-01-04T20:37:33.276052Z",
     "shell.execute_reply.started": "2026-01-04T13:06:10.780680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cba86f24a1641908ae51aabebf0f364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding passages (2 GPUs):   0%|          | 0/42768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (1368573, 768)\n"
     ]
    }
   ],
   "source": [
    "passage_embeddings = encode_passages(passages)\n",
    "print(\"Embedding shape:\", passage_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:33.278189Z",
     "iopub.status.busy": "2026-01-04T20:37:33.277821Z",
     "iopub.status.idle": "2026-01-04T20:37:43.052801Z",
     "shell.execute_reply": "2026-01-04T20:37:43.051892Z",
     "shell.execute_reply.started": "2026-01-04T20:37:33.278164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/passage.index' target='_blank'>/kaggle/working/passage.index</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/passage.index"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index size: 1368573\n"
     ]
    }
   ],
   "source": [
    "dim = passage_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "index.add(passage_embeddings)\n",
    "faiss.write_index(index, \"/kaggle/working/passage.index\")\n",
    "\n",
    "import pickle\n",
    "pickle.dump(passages, open(\"/kaggle/working/passages.pkl\", \"wb\"))\n",
    "\n",
    "print(\"FAISS index size:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:43.054631Z",
     "iopub.status.busy": "2026-01-04T20:37:43.053962Z",
     "iopub.status.idle": "2026-01-04T20:37:43.059460Z",
     "shell.execute_reply": "2026-01-04T20:37:43.058646Z",
     "shell.execute_reply.started": "2026-01-04T20:37:43.054605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def encode_question(question):\n",
    "    inputs = q_tokenizer(\n",
    "        question,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = q_encoder(**inputs).pooler_output  # ✅ correct for DPR\n",
    "\n",
    "    emb = emb.cpu().numpy()\n",
    "    faiss.normalize_L2(emb)\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:43.060809Z",
     "iopub.status.busy": "2026-01-04T20:37:43.060379Z",
     "iopub.status.idle": "2026-01-04T20:37:54.240020Z",
     "shell.execute_reply": "2026-01-04T20:37:54.239306Z",
     "shell.execute_reply.started": "2026-01-04T20:37:43.060764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dpr_retrieve(question, k=5):\n",
    "    q_emb = encode_question(question)\n",
    "    scores, indices = index.search(q_emb, k)\n",
    "    return [passages[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:54.242586Z",
     "iopub.status.busy": "2026-01-04T20:37:54.242330Z",
     "iopub.status.idle": "2026-01-04T20:37:54.705262Z",
     "shell.execute_reply": "2026-01-04T20:37:54.704418Z",
     "shell.execute_reply.started": "2026-01-04T20:37:54.242562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Passage 1 ---\n",
      "<P> Tracy McConnell ( colloquial : `` The Mother '' ) is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to \n",
      "\n",
      "--- Passage 2 ---\n",
      "<P> Tracy McConnell ( colloquial : `` The Mother '' ) is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to \n",
      "\n",
      "--- Passage 3 ---\n",
      "<P> Tracy McConnell ( colloquial : `` The Mother '' ) is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to \n",
      "\n",
      "--- Passage 4 ---\n",
      "<P> Tracy McConnell ( colloquial : `` The Mother '' ) is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to \n",
      "\n",
      "--- Passage 5 ---\n",
      "<P> Tracy McConnell ( colloquial : `` The Mother '' ) is the title character from the CBS television sitcom How I Met Your Mother . The show , narrated by Future Ted , tells the story of how Ted Mosby met The Mother . Tracy McConnell appears in 8 episodes from `` Lucky Penny '' to `` The Time Travelers '' as an unseen character ; she was first seen fully in `` Something New '' and was promoted to \n"
     ]
    }
   ],
   "source": [
    "question = \"who is the mother in how i met your mother\"\n",
    "\n",
    "retrieved = dpr_retrieve(question, k=5)\n",
    "\n",
    "for i, p in enumerate(retrieved, 1):\n",
    "    print(f\"\\n--- Passage {i} ---\")\n",
    "    print(p[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:54.706493Z",
     "iopub.status.busy": "2026-01-04T20:37:54.706207Z",
     "iopub.status.idle": "2026-01-04T20:37:55.093866Z",
     "shell.execute_reply": "2026-01-04T20:37:55.093054Z",
     "shell.execute_reply.started": "2026-01-04T20:37:54.706462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 631127  956634  857923  594217 1146010]]\n"
     ]
    }
   ],
   "source": [
    "scores, indices = index.search(encode_question(\"test question\"), 3)\n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:55.095223Z",
     "iopub.status.busy": "2026-01-04T20:37:55.094907Z",
     "iopub.status.idle": "2026-01-04T20:37:55.100923Z",
     "shell.execute_reply": "2026-01-04T20:37:55.100220Z",
     "shell.execute_reply.started": "2026-01-04T20:37:55.095198Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings are not collapsed\n",
    "np.allclose(passage_embeddings[0], passage_embeddings[1])\n",
    "# → False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:55.102404Z",
     "iopub.status.busy": "2026-01-04T20:37:55.101980Z",
     "iopub.status.idle": "2026-01-04T20:37:55.114481Z",
     "shell.execute_reply": "2026-01-04T20:37:55.113724Z",
     "shell.execute_reply.started": "2026-01-04T20:37:55.102370Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal == len(passages)\n",
    "# → True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:37:55.115622Z",
     "iopub.status.busy": "2026-01-04T20:37:55.115289Z",
     "iopub.status.idle": "2026-01-04T20:37:55.126437Z",
     "shell.execute_reply": "2026-01-04T20:37:55.125797Z",
     "shell.execute_reply.started": "2026-01-04T20:37:55.115595Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='passage.index' target='_blank'>passage.index</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/passage.index"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# This points to the file in your working directory\n",
    "FileLink(r'passage.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T20:39:41.318113Z",
     "iopub.status.busy": "2026-01-04T20:39:41.317526Z",
     "iopub.status.idle": "2026-01-04T20:39:43.080018Z",
     "shell.execute_reply": "2026-01-04T20:39:43.079336Z",
     "shell.execute_reply.started": "2026-01-04T20:39:41.318082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='passages.pkl' target='_blank'>passages.pkl</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/passages.pkl"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(passages, open(\"/kaggle/working/passages.pkl\", \"wb\"))\n",
    "FileLink(r'passages.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2912461,
     "sourceId": 11312647,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
